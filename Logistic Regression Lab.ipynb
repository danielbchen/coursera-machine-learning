{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "import statistics\n",
    "import scipy.optimize as opt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import jaccard_score\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Load in data and Select Model Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'https://raw.githubusercontent.com/kvinlazy/Dataset/master/ChurnData.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "df = df[['tenure', 'age', 'address', 'income', 'ed', 'employ', 'equip', 'callcard', 'wireless', 'churn']]\n",
    "df.churn = df.churn.astype('int') # Need to coerce outcome variable to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 200 rows and 10 columns in the data. The columns are named: tenure, age, address, income, ed, employ, equip, callcard, wireless, churn\n"
     ]
    }
   ],
   "source": [
    "df_names = df.columns.values.tolist()\n",
    "print(\n",
    "    f'There are {len(df)} rows and {len(df.columns)} columns in the data.',\n",
    "    f'The columns are named: {\", \".join([name for name in df_names])}'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll need to select our target and feature as well as normalize our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.asarray(df[['tenure', 'age', 'address', 'income', 'ed', 'employ', 'equip']])\n",
    "y = np.asarray(df.churn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean is -0.0 and the standard deviation is  1.0\n"
     ]
    }
   ],
   "source": [
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "\n",
    "# Check that we have a standard deviation of 1 and mean of 0\n",
    "flattened = []\n",
    "for lst in X:\n",
    "    for sublist in lst:\n",
    "        flattened.append(sublist)\n",
    "\n",
    "print(\n",
    "    f'The mean is {np.round(np.mean(flattened), 1)} and the standard deviation is',\n",
    "    f' {np.round(statistics.stdev(flattened), 1)}'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (160, 7) (160,)\n",
      "Test set: (40, 7) (40,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3)\n",
    "print('Train set:', X_train.shape, y_train.shape)\n",
    "print('Test set:', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.01, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.01, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=0.01, solver='liblinear')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit = LogisticRegression(C=0.01, solver='liblinear')\n",
    "logit.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = logit.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the above predicted the class of an observation, we can also retrieve the probability that an individual will be in each class by calling on the `predict_proba` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.40130629, 0.59869371],\n",
       "       [0.54455897, 0.45544103],\n",
       "       [0.49631135, 0.50368865],\n",
       "       [0.5432107 , 0.4567893 ],\n",
       "       [0.50668766, 0.49331234],\n",
       "       [0.51800365, 0.48199635],\n",
       "       [0.70742493, 0.29257507],\n",
       "       [0.60829538, 0.39170462],\n",
       "       [0.49611884, 0.50388116],\n",
       "       [0.37389734, 0.62610266]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat_prob = logit.predict_proba(X_test)\n",
    "yhat_prob[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above returns two columns because there are two possible classes. The first column predicts the probablity of being in class 0 and the second returns the probablity of being in class 1. `sklearn` will return one column for each class ordered by the label of the class. The probability of each row will sum to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because an array of nested lists can be difficult to work with, we can also transform the output into a pandas data frame if we ever needed to work with the probabilities directly. Additionally, we can easily check to see that the sum of the probabilities for each observation for each class will sum to one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range(1, 40)\n"
     ]
    }
   ],
   "source": [
    "class0_probabilities = []\n",
    "class1_probabilities = []\n",
    "for lst in yhat_prob:\n",
    "    for idx, prob in enumerate(lst):\n",
    "        if idx == 0:\n",
    "            class0_probabilities.append(prob)\n",
    "        elif idx == 1:\n",
    "            class1_probabilities.append(prob)\n",
    "\n",
    "prob_df = pd.DataFrame({\n",
    "    'observation_id': [num for num in range(1, len(class0_probabilities) + 1)],\n",
    "    'class0_prob': class0_probabilities,\n",
    "    'class1_prob': class1_probabilities\n",
    "})\n",
    "\n",
    "prob_df['prob_sum'] = prob_df['class0_prob'] + prob_df['class1_prob']\n",
    "\n",
    "prob_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Model Evaluation\n",
    "\n",
    "We can use the jaccard score which is the size of the intersection divided by the union of the two label sets. If the entire set of the predicted labels matches the true set of labels, then the accuracy is 1. The score ranges from 0 to 1, with 1 being a \"better\" score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jaccard_score(y_true=y_test, y_pred=yhat, pos_label=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f90806bb580>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_true=y_test, y_pred=yhat, labels=[1, 0]) \n",
    "cmd = ConfusionMatrixDisplay(cm, display_labels=[1, 0])\n",
    "cmd.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the confusion matrix above, the number of correctly predicted classes runs along the diagonal. The logistic regression model predicted 22 observations to be in class 0 and 22 of them were indeed in class 0. The model also predicted 7 observations to be in class 1 and 7 of them were indeed in class 1. This leads to an accuracy score of:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.725"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_true=y_test, y_pred=yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
